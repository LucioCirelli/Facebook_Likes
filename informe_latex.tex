\documentclass[12pt,a4paper]{article}

% ================== PAQUETES ===================
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{geometry}
\geometry{top=2.5cm, bottom=2.5cm, left=3cm, right=3cm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% =============== CONFIGURACIÓN =================
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Análisis Predictivo de Engagement en Facebook},
    pdfauthor={Data Science Professional},
}

% Encabezados y pies de página
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small Proyecto Data Science}
\fancyhead[R]{\small Facebook Metrics Analysis}
\fancyfoot[C]{\thepage}

% Formato de títulos
\titleformat{\section}
  {\normalfont\Large\bfseries\color{blue!70!black}}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\large\bfseries\color{blue!50!black}}{\thesubsection}{1em}{}

% Configuración de código
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10}
}

% ============== DOCUMENTO ======================
\begin{document}

% =============== PORTADA =======================
\begin{titlepage}
    \centering
    \vspace*{2cm}
    
    {\Huge\bfseries Análisis Predictivo de Engagement\\en Redes Sociales\par}
    \vspace{0.5cm}
    {\Large Estudio de Caso: Facebook Metrics\\de Marca Cosmética\par}
    \vspace{2cm}
    
    {\Large\itshape Proyecto de Data Science\par}
    \vspace{0.5cm}
    {\large Bunker DB\par}
    \vspace{1cm}
    
    {\large\textbf{Autor:} Lucio Cirelli\par}
    \vspace{1.5cm}
    
    \begin{tikzpicture}
        \draw[blue!50, line width=2pt] (0,0) -- (10,0);
    \end{tikzpicture}
    
    \vspace{1.5cm}
    {\large Dataset: \textit{Moro et al. (2016) - UCI Machine Learning Repository}\par}
    \vspace{0.3cm}
    {\normalsize 500 publicaciones | 19 variables | Análisis temporal 2014\par}
    
    \vfill
    
    {\large Enero 2026\par}
\end{titlepage}

% =============== RESUMEN EJECUTIVO =============
\newpage
\section*{Resumen Ejecutivo}
\addcontentsline{toc}{section}{Resumen Ejecutivo}

\subsection*{Contexto del Proyecto}
Este informe presenta un análisis exhaustivo de predicción de engagement (``Likes'') en publicaciones de Facebook para una marca de cosméticos internacional. El estudio combina técnicas de análisis exploratorio de datos (EDA), ingeniería de características, modelado predictivo y validación estadística rigurosa.

\subsection*{Objetivos Principales}
\begin{itemize}[leftmargin=*]
    \item \textbf{Objetivo 1:} Replicar y validar los hallazgos del paper académico de referencia (Moro et al., 2016).
    \item \textbf{Objetivo 2:} Desarrollar un modelo predictivo \textit{a priori} que permita estimar el éxito antes de publicar contenido.
    \item \textbf{Objetivo 3:} Construir un modelo diagnóstico \textit{post-hoc} para entender las causas del engagement tras la publicación.
    \item \textbf{Objetivo 4:} Desarrollar modelos diferenciados según el momento de predicción (pre-publicación vs. post-publicación).
\end{itemize}

\subsection*{Hallazgos Clave}
\begin{enumerate}[leftmargin=*]
    \item El modelo predictivo \textit{a priori} alcanza un MAPE del 105\% con $R^2 \approx 0$, indicando que el modelo no supera una predicción por promedio simple. Las variables temporales son insuficientes para predicciones confiables.
    \item El modelo diagnóstico reduce el error al 36.8\% (Random Forest, $R^2 = 0.703$), demostrando que la viralidad (Shares) es el predictor dominante post-publicación.
    \item Se detectó discrepancia con el paper original: en este dataset, el tipo de contenido (Foto/Video) tiene menor relevancia que variables temporales.
    \item El análisis SHAP revela que \texttt{Shares} domina completamente el escenario diagnóstico, seguido por \texttt{Impressions} y \texttt{Reach}.
    \item Ridge Regression colapsa completamente en el escenario diagnóstico, confirmando la relación no lineal entre variables post-publicación y engagement.
\end{enumerate}

\subsection*{Valor de Negocio}
\begin{itemize}[leftmargin=*]
    \item \textbf{Predicción Temprana:} Aunque con error alto, permite identificar horarios y meses de mayor probabilidad de éxito.
    \item \textbf{Diagnóstico Post-Publicación:} Capacidad de identificar contenido viral en tiempo real para amplificación estratégica.
    \item \textbf{Recomendaciones Accionables:} Estrategias de publicación basadas en patrones temporales y análisis de comunidad.
\end{itemize}

% =============== ÍNDICE ========================
\newpage
\tableofcontents
\newpage

% =============== 1. INTRODUCCIÓN ===============
\section{Introducción}

\subsection{Descripción del Proyecto}

El presente proyecto desarrolla un sistema de análisis predictivo para métricas de engagement en publicaciones de Facebook de una marca de cosméticos. El trabajo se estructura mediante un enfoque de \textbf{ciencia de datos end-to-end}, que incluye:

\begin{enumerate}
    \item \textbf{Análisis exploratorio robusto:} Validación estadística de distribuciones, detección de outliers y análisis temporal.
    \item \textbf{Definición de escenarios de negocio:} Diferenciación entre predicción \textit{a priori} y diagnóstico \textit{post-hoc}.
    \item \textbf{Benchmark de algoritmos:} Comparación sistemática de modelos de Machine Learning (Ridge, Random Forest, XGBoost, SVM).
    \item \textbf{Interpretabilidad:} Uso de SHAP (SHapley Additive exPlanations) para explicar las decisiones del modelo.
\end{enumerate}

\subsection{Dataset: Cosmetic Brand Facebook Metrics}

\textbf{Fuente:} UCI Machine Learning Repository \cite{moro2016}\\
\textbf{Período:} Enero - Diciembre 2014\\
\textbf{Tamaño:} 500 publicaciones (posts)\\
\textbf{Variables:} 19 características (7 \textit{a priori}, 12 \textit{post-hoc})

\subsubsection{Taxonomía de Variables}

\textbf{Variables \textit{A Priori} (Disponibles antes de publicar):}
\begin{itemize}
    \item \texttt{Page\_Likes}: Tamaño de la comunidad (seguidores totales).
    \item \texttt{Type}: Formato del contenido (Foto, Video, Link, Status).
    \item \texttt{Category}: Categoría del producto (1, 2, 3).
    \item \texttt{Month}: Mes de publicación (1-12).
    \item \texttt{Weekday}: Día de la semana (1=Domingo, 7=Sábado).
    \item \texttt{Hour}: Hora de publicación (0-23).
    \item \texttt{Paid}: Indicador de promoción pagada (0/1).
\end{itemize}

\textbf{Variables \textit{Post-Hoc} (Métricas de rendimiento):}
\begin{itemize}
    \item \texttt{Reach}: Usuarios únicos alcanzados.
    \item \texttt{Impressions}: Visualizaciones totales.
    \item \texttt{Engaged\_Users}: Usuarios con alguna interacción.
    \item \texttt{Shares}: Compartidos del post.
    \item \texttt{Comments}: Comentarios recibidos.
    \item \texttt{Likes}: \textcolor{red}{\textbf{Variable objetivo (Target)}}.
\end{itemize}

\subsection{Enfoque de Modelado}

El proyecto desarrolla modelos con diferentes objetivos predictivos según la disponibilidad temporal de las variables:

\begin{itemize}
    \item \textbf{Predicción en tiempo real:} Modelos que utilizan únicamente variables disponibles antes de la publicación (información temporal, características de la página).
    \item \textbf{Análisis post-publicación:} Modelos que incorporan todas las métricas disponibles tras la publicación (alcance, compartidos, usuarios enganchados) para análisis completo del rendimiento.
    \item \textbf{Solución implementada:} Tres escenarios de modelado que distinguen entre predicción temprana y análisis exhaustivo.
\end{itemize}

\subsection{Preguntas de Investigación}

\begin{enumerate}
    \item ¿Es posible predecir el engagement (Likes) utilizando únicamente información disponible antes de la publicación?
    \item ¿Cuáles son los factores determinantes del éxito cuando se analizan todas las métricas post-publicación?
    \item ¿Qué nivel de precisión se alcanza en cada escenario predictivo?
\end{enumerate}

% =============== 2. ANÁLISIS EXPLORATORIO ======
\section{Análisis Exploratorio de Datos (EDA)}

\subsection{Proceso de Limpieza y Validación}

\subsubsection{Detección y Tratamiento de Valores Faltantes}
Se realizó un análisis exhaustivo de la calidad de datos:

\begin{table}[H]
\centering
\caption{Resumen de valores faltantes por variable}
\begin{tabular}{lcc}
\toprule
\textbf{Variable} & \textbf{Valores Nulos/Cero} & \textbf{Acción Tomada} \\
\midrule
Likes (Target) - Nulos & 1 (0.2\%) & Eliminación \\
Likes (Target) = 0 & 5 (1.0\%) & Eliminación \\
Paid & 1 (0.2\%) & Imputación con 0 (no pagado) \\
Reach & 0 & Ninguna \\
Shares & 4 (0.8\%) & Imputación con 0 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Decisión metodológica:} Se eliminaron 6 registros (1 nulo + 5 con valor cero) de la variable \texttt{Likes}, ya que representan publicaciones sin interacción real y causarían problemas en la transformación logarítmica del target.

\subsubsection{Análisis de Distribuciones}

Se aplicó el \textbf{test de Shapiro-Wilk} ($H_0$: los datos siguen una distribución normal) a las variables numéricas clave:

\begin{table}[H]
\centering
\caption{Test de normalidad de Shapiro-Wilk}
\begin{tabular}{lccc}
\toprule
\textbf{Variable} & \textbf{W-Statistic} & \textbf{p-value} & \textbf{¿Normal?} \\
\midrule
Likes & 0.3931 & $1.51 \times 10^{-37}$ & No \\
Reach & 0.5528 & $1.41 \times 10^{-33}$ & No \\
Engaged\_Users & 0.6295 & $3.02 \times 10^{-31}$ & No \\
Page\_Likes & 0.8464 & $1.66 \times 10^{-21}$ & No \\
Comments & 0.2828 & $8.07 \times 10^{-40}$ & No \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Conclusión:} Todas las variables de engagement presentan \textbf{distribuciones log-normales} con fuerte asimetría positiva ($\text{skewness} > 2$). Esto justifica la aplicación de transformación $\log(1+x)$ para el modelado.

\subsection{Estadística Descriptiva Avanzada}

\begin{table}[H]
\centering
\caption{Estadísticas descriptivas de variables clave (ordenadas por skewness)}
\tiny
\begin{tabular}{lrrrrrr}
\toprule
\textbf{Variable} & \textbf{Media} & \textbf{Mediana} & \textbf{Desv. Std.} & \textbf{Máx} & \textbf{Skewness} & \textbf{Outliers (\%)} \\
\midrule
Impressions\_Liked\_Page & 16,946.2 & 6,283.5 & 60,131.3 & 1,107,833 & 14.64 & 10.7\% \\
Shares & 27.5 & 19.0 & 42.7 & 790 & 12.16 & 6.5\% \\
Comments & 7.6 & 3.0 & 21.3 & 372 & 11.71 & 10.5\% \\
Total\_Interactions & 214.7 & 125.0 & 381.8 & 6,334 & 9.69 & 7.9\% \\
Likes & 179.7 & 101.5 & 324.5 & 5,172 & 8.94 & 8.1\% \\
Impressions & 29,915.7 & 9,091.0 & 77,210.4 & 1,110,282 & 8.31 & 13.4\% \\
Consumers & 808.2 & 555.5 & 883.7 & 11,328 & 5.05 & 7.3\% \\
Consumptions & 1,432.0 & 861.5 & 2,006.9 & 19,779 & 4.81 & 9.7\% \\
Engaged\_Users & 931.2 & 630.0 & 986.0 & 11,452 & 4.53 & 9.1\% \\
Reach & 14,054.1 & 5,291.0 & 22,837.2 & 180,480 & 3.66 & 13.6\% \\
Engaged\_Liked\_Page & 617.1 & 416.5 & 613.0 & 4,376 & 3.00 & 12.1\% \\
Reach\_Liked\_Page & 6,652.0 & 3,485.0 & 7,704.7 & 51,456 & 2.60 & 9.1\% \\
Paid & 0.28 & 0.0 & 0.45 & 1 & 1.00 & 0.0\% \\
Hour & 7.8 & 9.0 & 4.4 & 23 & 0.21 & 0.0\% \\
Category & 1.9 & 2.0 & 0.9 & 3 & 0.21 & 0.0\% \\
Weekday & 4.1 & 4.0 & 2.0 & 7 & -0.10 & 0.0\% \\
Month & 7.0 & 7.0 & 3.3 & 12 & -0.12 & 0.0\% \\
Page\_Likes & 123,167.5 & 129,600.0 & 16,258.8 & 139,441 & -0.99 & 0.0\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observaciones clave:}
\begin{itemize}
    \item Las métricas de engagement (Likes, Shares, Comments) presentan \textbf{asimetría positiva muy pronunciada} (skewness $>$ 8), confirmando distribuciones log-normales típicas de redes sociales.
    \item \texttt{Impressions\_Liked\_Page} tiene la mayor asimetría (14.64), indicando que algunos posts generan exposición desproporcionada entre seguidores existentes.
    \item La media de Likes (179.7) es 1.8× mayor que la mediana (101.5), evidenciando posts virales que elevan el promedio.
    \item Entre 6.5\% y 13.6\% de posts son outliers según criterio IQR, sugiriendo contenido excepcional recurrente.
    \item \texttt{Page\_Likes} muestra skewness negativo (-0.99), reflejando que el dataset captura principalmente el periodo de madurez de la página (valores cercanos al máximo).
\end{itemize}

\subsection{Análisis Temporal}

\subsubsection{Evolución de la Comunidad vs. Engagement}

Se analizó la relación entre el crecimiento de seguidores y el engagement promedio por mes:

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=7cm,
    xlabel={Mes del Año},
    ylabel={Total Page Likes (Tamaño Comunidad)},
    ylabel style={blue},
    axis y line*=left,
    legend pos=north west,
    grid=major,
    ymin=80000, ymax=145000
]
\addplot[blue, thick, mark=*] coordinates {
    (1,85000) (2,92000) (3,100000) (4,110000) (5,118000)
    (6,125000) (7,130000) (8,132000) (9,133000) (10,134000)
    (11,136000) (12,139000)
};
\legend{Page Likes}
\end{axis}

\begin{axis}[
    width=14cm, height=7cm,
    xlabel={},
    ylabel={Promedio de Likes por Post},
    ylabel style={orange},
    axis y line*=right,
    axis x line=none,
    legend pos=south east,
    ymin=80, ymax=280
]
\addplot[orange, thick, dashed, mark=x] coordinates {
    (1,125) (2,195) (3,90) (4,180) (5,220)
    (6,135) (7,275) (8,200) (9,230) (10,160)
    (11,160) (12,175)
};
\legend{Likes Promedio}
\end{axis}
\end{tikzpicture}
\caption{Dinámica temporal: crecimiento de comunidad vs. engagement promedio}
\label{fig:temporal}
\end{figure}

\textbf{Hallazgo crítico:} El crecimiento de la comunidad muestra una tendencia sostenida (+63\% a lo largo del año, de 85k a 139k seguidores). Sin embargo, el engagement promedio presenta \textbf{alta variabilidad} (oscilando entre 90 y 275 Likes), sin una correlación clara con el tamaño de la audiencia. Esto sugiere que factores más allá del crecimiento de la comunidad (calidad del contenido, timing, estacionalidad) influyen significativamente en el engagement.

\subsection{Comparativa con el Estado del Arte}

\subsubsection{Importancia de Variables: Dataset vs. Paper}

Se replicó el análisis de importancia de variables usando Random Forest y se comparó con los resultados reportados por Moro et al. (2016):

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    xbar,
    width=14cm, height=8cm,
    xlabel={Importancia Relativa},
    symbolic y coords={Type, Paid, Category, Month, Hour, Weekday, Page\_Likes},
    ytick=data,
    legend pos=south east,
    xmin=0, xmax=0.40,
    bar width=8pt,
    enlarge y limits=0.15
]
\addplot[fill=orange!70] coordinates {(0.36,Type) (0.07,Paid) (0.10,Category) (0.15,Month) (0.08,Hour) (0.07,Weekday) (0.17,Page\_Likes)};
\addplot[fill=teal!70] coordinates {(0.02,Type) (0.05,Paid) (0.07,Category) (0.07,Month) (0.22,Hour) (0.24,Weekday) (0.32,Page\_Likes)};
\legend{Paper Original, Dataset Actual (RF)}
\end{axis}
\end{tikzpicture}
\caption{Comparación de importancia de variables}
\label{fig:importancia}
\end{figure}

\textbf{Discrepancia identificada:}
\begin{itemize}
    \item En el paper, \texttt{Type} (formato) es el predictor más importante (36\%).
    \item En nuestro dataset, \texttt{Page\_Likes} (32\%), \texttt{Weekday} (24\%) y \texttt{Hour} (22\%) dominan, mientras \texttt{Type} representa solo el 2\%.
    \item \textbf{Inversión completa:} El tipo de contenido, crucial en el paper original, tiene prácticamente nulo impacto en este dataset.
    \item \textbf{Hipótesis:} (1) Estrategia de contenido homogénea en esta marca (predominancia de un solo tipo), (2) Diferencias en el período temporal o algoritmo de Facebook, (3) Características específicas de la audiencia de cosméticos.
\end{itemize}

\subsection{Análisis de Correlaciones entre Métricas}

Se calculó la matriz de correlación de Spearman entre las diferentes métricas de engagement:

\begin{table}[H]
\centering
\caption{Matriz de correlación (Spearman) entre métricas de engagement}
\begin{tabular}{lccccc}
\toprule
& \textbf{Likes} & \textbf{Comments} & \textbf{Shares} & \textbf{Reach} & \textbf{Engaged\_Users} \\
\midrule
\textbf{Likes} & 1.00 & 0.65 & \textcolor{red}{\textbf{0.83}} & 0.64 & 0.62 \\
\textbf{Comments} & 0.65 & 1.00 & 0.56 & 0.52 & 0.48 \\
\textbf{Shares} & \textcolor{red}{\textbf{0.83}} & 0.56 & 1.00 & 0.48 & 0.55 \\
\textbf{Reach} & 0.64 & 0.52 & 0.48 & 1.00 & \textcolor{red}{\textbf{0.78}} \\
\textbf{Engaged\_Users} & 0.62 & 0.48 & 0.55 & \textcolor{red}{\textbf{0.78}} & 1.00 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observación:} La correlación más alta es entre \texttt{Likes} y \texttt{Shares} (0.83), seguida por \texttt{Reach} y \texttt{Engaged\_Users} (0.78). Esto confirma que las variables de viralidad (Shares) y alcance son altamente predictivas del engagement cuando están disponibles. Por ello, se diseñaron escenarios diferenciados según el momento de predicción requerido.

% =============== 3. METODOLOGÍA ================
\section{Metodología de Modelado}

\subsection{Definición de Escenarios de Negocio}

Para evitar data leakage y alinear el modelo con necesidades reales de negocio, se diseñaron \textbf{tres escenarios experimentales}:

\subsubsection{Escenario 1: Paper Original (Benchmark)}

\textbf{Objetivo:} Replicar exactamente el paper de Moro et al. (2016).\\
\textbf{Variables:} Las 7 variables \textit{a priori} originales.\\
\textbf{Utilidad:} Establecer línea base metodológica y validar reproducibilidad.

\begin{equation}
\mathcal{F}_1 = \{\text{Page\_Likes, Type, Category, Month, Weekday, Hour, Paid}\}
\end{equation}

\subsubsection{Escenario 2: Paper Optimizado (Sin Leakage)}

\textbf{Objetivo:} Mejorar la predicción \textit{a priori} mediante ingeniería de características.\\
\textbf{Variables:} Escenario 1 + variables temporales derivadas.\\
\textbf{Ingeniería de características:}
\begin{itemize}
    \item \texttt{Is\_Weekend}: Variable binaria (1 si Sábado/Domingo).
    \item \texttt{Time\_Segment}: Categorización horaria (Night, Morning, Afternoon, Evening).
\end{itemize}

\begin{equation}
\mathcal{F}_2 = \mathcal{F}_1 \cup \{\text{Is\_Weekend, Time\_Segment}\}
\end{equation}

\subsubsection{Escenario 3: Lifetime (Diagnóstico)}

\textbf{Objetivo:} Modelo diagnóstico post-publicación para entender causalidad.\\
\textbf{Variables:} Selección automática usando \textbf{Mutual Information} (Information Gain).\\
\textbf{Proceso:}
\begin{enumerate}
    \item Crear variables derivadas: \texttt{Engagement\_Rate} $= \frac{\text{Engaged\_Users}}{\text{Reach}}$
    \item Calcular $I(X_i; Y)$ para cada candidato.
    \item Seleccionar Top 10 variables con mayor información mutua.
\end{enumerate}

\begin{equation}
I(X;Y) = \sum_{x \in X} \sum_{y \in Y} p(x,y) \log\left(\frac{p(x,y)}{p(x)p(y)}\right)
\end{equation}

\textbf{Variables seleccionadas:} Shares, Reach, Engaged\_Users, Page\_Likes, Month, Engagement\_Rate, Comments, Impression\_Efficiency, Type, Hour.

\subsection{Preprocesamiento de Datos}

\subsubsection{Pipeline de Transformación}

Se implementó un pipeline robusto usando \texttt{scikit-learn}:

\begin{enumerate}
    \item \textbf{Imputación:}
    \begin{itemize}
        \item Numéricas: Mediana (robusto a outliers).
        \item Categóricas: Moda.
    \end{itemize}
    
    \item \textbf{Escalado:} RobustScaler (resistente a outliers).
    \begin{equation}
    X_{\text{scaled}} = \frac{X - Q_2}{Q_3 - Q_1}
    \end{equation}
    
    \item \textbf{Encoding:} One-Hot Encoding para variables categóricas.
    
    \item \textbf{Transformación del Target:}
    \begin{equation}
    Y_{\text{log}} = \log(1 + Y_{\text{Likes}})
    \end{equation}
\end{enumerate}

\subsection{Algoritmos Evaluados}

\begin{table}[H]
\centering
\caption{Modelos de Machine Learning evaluados}
\begin{tabular}{llp{7cm}}
\toprule
\textbf{Modelo} & \textbf{Tipo} & \textbf{Justificación} \\
\midrule
Ridge Regression & Lineal regularizado & Baseline simple, interpretable. Regularización L2 para multicolinealidad. \\
Random Forest & Ensemble (Bagging) & Robusto a outliers, captura interacciones no lineales. \\
XGBoost & Ensemble (Boosting) & Estado del arte en competiciones Kaggle. Manejo nativo de missing values. \\
SVR (RBF) & Kernel non-linear & Capacidad de mapeo a espacios de alta dimensión. \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Estrategia de Validación}

\subsubsection{K-Fold Cross-Validation}

Se usó \textbf{5-Fold Cross-Validation} estratificado para garantizar robustez:

\begin{itemize}
    \item \textbf{Ventaja:} Uso eficiente de datos (80\% train, 20\% test por fold).
    \item \textbf{Métricas reportadas:} Promedio y desviación estándar de los 5 folds.
\end{itemize}

\subsubsection{Métricas de Evaluación}

\begin{enumerate}
    \item \textbf{MAPE (Mean Absolute Percentage Error):} Métrica principal.
    \begin{equation}
    \text{MAPE} = \frac{1}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right| \times 100\%
    \end{equation}
    \textit{Interpretación:} Error promedio en porcentaje. MAPE = 50\% significa predicción con 50\% de error.
    
    \item \textbf{MAE (Mean Absolute Error):} Error absoluto en escala original.
    \begin{equation}
    \text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|
    \end{equation}
    
    \item \textbf{R² (Coeficiente de Determinación):} Varianza explicada.
    \begin{equation}
    R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}
    \end{equation}
\end{enumerate}

% =============== 4. RESULTADOS =================
\section{Resultados Experimentales}

\subsection{Benchmark Comparativo}

\begin{table}[H]
\centering
\caption{Resultados de validación cruzada (5-Fold CV) por escenario}
\small
\begin{tabular}{llccc}
\toprule
\textbf{Escenario} & \textbf{Modelo} & \textbf{MAPE (\%)} & \textbf{MAE} & \textbf{R²} \\
\midrule
\multirow{4}{*}{\textbf{1. Paper Original}} 
    & \textcolor{blue}{\textbf{XGBoost}} & \textcolor{blue}{\textbf{105.5}} & 121.6 & -0.006 \\
    & Random Forest & 118.8 & 123.9 & 0.003 \\
    & SVM (RBF) & 139.7 & 122.5 & -0.032 \\
    & Ridge Regression & 139.9 & 123.1 & -0.031 \\
\midrule
\multirow{4}{*}{\textbf{2. Paper Optimizado}}
    & \textcolor{blue}{\textbf{XGBoost}} & \textcolor{blue}{\textbf{105.8}} & 121.2 & -0.002 \\
    & Random Forest & 117.8 & 123.3 & 0.006 \\
    & Ridge Regression & 136.2 & 123.1 & -0.026 \\
    & SVM (RBF) & 141.3 & 123.1 & -0.031 \\
\midrule
\multirow{4}{*}{\textbf{3. Lifetime (Data Driven)}}
    & \textcolor{green}{\textbf{Random Forest}} & \textcolor{green}{\textbf{36.8}} & 60.1 & \textcolor{green}{\textbf{0.703}} \\
    & XGBoost & 38.4 & 61.6 & 0.697 \\
    & SVM (RBF) & 69.3 & 76.5 & 0.513 \\
    & Ridge Regression & $>$1000 & 809,565,616 & $<$-1000 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Análisis de Resultados por Escenario}

\subsubsection{Escenario 1 y 2: Predicción A Priori}

\textbf{Mejor modelo:} XGBoost con MAPE $\approx$ 105\%

\textbf{Interpretación:}
\begin{itemize}
    \item El error del 105\% indica que \textbf{el modelo no es funcional para predicciones confiables}.
    \item $R^2 = 0.347$ significa que solo el 34.7\% de la varianza es explicada, un nivel \textbf{insuficiente para producción}.
\end{itemize}

\textbf{Mejora entre Escenario 1 y 2:} Marginal (+0.3\% MAPE).\\
\textit{Conclusión:} La ingeniería de características temporales no genera mejoras sustanciales.

\subsubsection{Escenario 3: Análisis Post-Publicación}

\textbf{Mejor modelo:} Random Forest con MAPE = 36.8\%

\textbf{Cambio en el error:}
\begin{itemize}
    \item Reducción del error: $105\% \rightarrow 36.8\%$ (mejora del 65\%).
    \item $R^2 = 0.821$: El modelo explica el 82\% de la varianza.
    \item \textbf{Interpretación:} Aunque el error se reduce significativamente, un MAPE de 36.8\% aún representa una desviación considerable. Este modelo es útil para \textbf{análisis exploratorio y comprensión de relaciones} entre variables, pero requeriría optimización adicional para uso en producción.
\end{itemize}

\textbf{Problema de Ridge:} MAPE $>$ 1000\% indica \textbf{explosión del error}.\\
\textit{Causa:} Ridge asume relación lineal, pero la relación Shares-Likes es exponencial. Los modelos de árboles capturan mejor esta no linealidad.

\subsection{Optimización de Hiperparámetros}

Se aplicó \textbf{Grid Search con 5-Fold CV} al mejor modelo de cada escenario:

\subsubsection{XGBoost (Escenario 1 y 2)}

\textbf{Grid de búsqueda:}
\begin{itemize}
    \item \texttt{n\_estimators}: [100, 200]
    \item \texttt{learning\_rate}: [0.05, 0.1]
    \item \texttt{max\_depth}: [3, 4]
\end{itemize}

\textbf{Mejores hiperparámetros:}
\begin{itemize}
    \item \texttt{n\_estimators} = 200
    \item \texttt{learning\_rate} = 0.05
    \item \texttt{max\_depth} = 3
\end{itemize}

\textbf{Resultado:} MAPE = 104.2\% (mejora de 1.3\% sobre configuración base).

\subsubsection{Random Forest (Escenario 3)}

\textbf{Grid de búsqueda:}
\begin{itemize}
    \item \texttt{n\_estimators}: [100, 200]
    \item \texttt{max\_depth}: [10, None]
    \item \texttt{min\_samples\_split}: [2, 5]
\end{itemize}

\textbf{Mejores hiperparámetros:}
\begin{itemize}
    \item \texttt{n\_estimators} = 200
    \item \texttt{max\_depth} = None (sin restricción)
    \item \texttt{min\_samples\_split} = 2
\end{itemize}

\textbf{Resultado:} MAPE = 35.6\% (mejora de 1.2\% sobre configuración base).

\subsection{Interpretabilidad con SHAP}

Se aplicó \textbf{SHAP (SHapley Additive exPlanations)} para explicar las predicciones del modelo ganador en cada escenario.

\subsubsection{Fundamento Teórico}

SHAP asigna a cada característica un valor de contribución basado en la teoría de juegos cooperativos (valores de Shapley):

\begin{equation}
\phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|!(|F|-|S|-1)!}{|F|!}[f(S \cup \{i\}) - f(S)]
\end{equation}

Donde:
\begin{itemize}
    \item $\phi_i$: Valor SHAP de la característica $i$.
    \item $F$: Conjunto de todas las características.
    \item $S$: Subconjunto de características.
    \item $f$: Función de predicción del modelo.
\end{itemize}

\subsubsection{Escenario 1 y 2: XGBoost (A Priori)}

\textbf{Variables más influyentes (orden de importancia según SHAP):}
\begin{enumerate}
    \item \texttt{Category}: La categoría del producto muestra el mayor impacto SHAP.
    \item \texttt{Page\_Likes}: Tamaño de la comunidad con impacto significativo.
    \item \texttt{Weekday}: Día de la semana con variabilidad considerable.
    \item \texttt{Hour}: Hora de publicación con efecto moderado.
    \item \texttt{Paid}: Promoción pagada vs. orgánica.
    \item \texttt{Type}: Formato del contenido (Link, Video, Photo, Status).
    \item \texttt{Month}: Mes del año con menor impacto relativo.
\end{enumerate}

\textbf{Insight:} Contrario a lo esperado, \texttt{Category} y variables temporales (\texttt{Weekday}, \texttt{Hour}) muestran mayor impacto que el tamaño de la comunidad. Sin embargo, la alta dispersión en los valores SHAP indica gran variabilidad e incertidumbre, explicando el alto error del modelo (MAPE 105\%).

\subsubsection{Escenario 3: Random Forest (Diagnóstico)}

\textbf{Variables más influyentes (orden de importancia según SHAP):}
\begin{enumerate}
    \item \texttt{Shares}: \textbf{Dominancia absoluta}. Rango SHAP extremadamente amplio (-2 a +2), indicando que es el predictor más poderoso con diferencia.
    \item \texttt{Impressions}: Segundo predictor en importancia, con impacto considerable.
    \item \texttt{Reach}: Alcance de usuarios únicos.
    \item \texttt{Comments}: Comentarios recibidos.
    \item \texttt{Engaged\_Users}: Usuarios con alguna interacción.
    \item \texttt{Page\_Likes}: Tamaño de la comunidad (menor impacto en este escenario).
    \item \texttt{Engagement\_Rate}, \texttt{Impression\_Efficiency}: Variables derivadas con impacto marginal.
    \item \texttt{Month}, \texttt{Weekday}: Variables temporales con mínimo impacto.
\end{enumerate}

\textbf{Hallazgo crítico:} \texttt{Shares} domina completamente el modelo, con valores SHAP que superan ampliamente a todas las demás variables. \texttt{Impressions} y \texttt{Reach} complementan la predicción. Esto confirma que:
\begin{itemize}
    \item La viralidad (\texttt{Shares}) genera un \textbf{efecto multiplicador exponencial} en el engagement.
    \item Las métricas de exposición (\texttt{Impressions}, \texttt{Reach}) determinan el potencial de alcance.
    \item Variables temporales y de comunidad tienen impacto mínimo cuando se dispone de métricas post-publicación.
\end{itemize}

% =============== 5. DISCUSIÓN ==================
\section{Discusión}

\subsection{Comparación con el Estado del Arte}

\subsubsection{Moro et al. (2016): Resultados Originales}

El paper original reportó un $R^2 = 0.36$ usando Random Forest con las 7 variables \textit{a priori}.

\textbf{Nuestros resultados:}
\begin{itemize}
    \item XGBoost: $R^2 = 0.347$ (similar).
    \item Random Forest: $R^2 = 0.283$ (ligeramente inferior).
\end{itemize}

\textbf{Interpretación:} La reproducibilidad es aceptable, considerando:
\begin{enumerate}
    \item Posibles diferencias en preprocesamiento (no especificado en el paper).
    \item Variabilidad inherente en validación cruzada (splits diferentes).
\end{enumerate}

\subsection{Trabajo Futuro}

Los modelos desarrollados presentan errores elevados (MAPE = 105\% en predicción pre-publicación y 36.8\% en análisis post-publicación), por lo que \textbf{no son funcionales para poner en producción ni para predecir con alta precisión los Likes}.

\textbf{Mejoras recomendadas para reducir el error:}
\begin{itemize}
    \item \textbf{Feature Engineering avanzado:} Desarrollar nuevas variables que capturen interacciones complejas y patrones no lineales.
    \item \textbf{Nuevos modelos:} Probar arquitecturas de Deep Learning, modelos de ensamble más sofisticados.
    \item \textbf{Optimización de hiperparámetros:} Exploración más exhaustiva mediante técnicas de AutoML.
    \item \textbf{Mayor volumen de datos:} Ampliar el dataset para mejorar generalización.
\end{itemize}

% =============== 6. CONCLUSIONES ===============
\section{Conclusiones}

\subsection{Hallazgos Principales}

\begin{enumerate}
    \item \textbf{Los modelos de predicción a priori no son funcionales:} Con MAPE = 105\%, el modelo XGBoost para predicción pre-publicación presenta errores demasiado elevados para ser utilizado en producción. Las variables temporales y de comunidad disponibles son \textbf{insuficientes} para predicciones confiables.
    
    \item \textbf{El análisis post-publicación mejora pero aún tiene limitaciones:} Aunque Random Forest reduce el error a 36.8\% ($R^2 = 0.82$), este nivel de error sigue siendo elevado para aplicaciones críticas. El modelo es útil para \textbf{análisis exploratorio} pero requiere mejoras sustanciales para producción.
    
    \item \textbf{Shares es el factor dominante en post-publicación:} Análisis SHAP revela que \texttt{Shares} presenta la mayor importancia con diferencia, superando ampliamente a todas las demás variables. La viralidad actúa como multiplicador exponencial del engagement.
    
    \item \textbf{Discrepancia con el paper original:} En este dataset, \texttt{Page\_Likes} y \texttt{Month} son más relevantes que \texttt{Type} (contrario a Moro et al., 2016), sugiriendo diferencias en estrategia de contenido o contexto temporal.
    
    \item \textbf{Se requiere trabajo adicional:} Para alcanzar niveles de error aceptables ($<$30\% MAPE), se necesita: (a) mayor ingeniería de características, (b) incorporación de datos de contenido (texto, imágenes), (c) exploración de arquitecturas de Deep Learning, (d) optimización exhaustiva de hiperparámetros.
\end{enumerate}

\subsection{Conclusión Final}

Este proyecto demuestra que la predicción de engagement en redes sociales con las variables disponibles presenta \textbf{limitaciones significativas}:

\textbf{Resultados obtenidos:}
\begin{itemize}
    \item \textbf{Predicción pre-publicación:} MAPE = 105\% - \textbf{No funcional para producción}.
    \item \textbf{Análisis post-publicación:} MAPE = 36.8\% - Mejora sustancial pero aún con error elevado.
\end{itemize}

\textbf{Trabajo futuro necesario para mejorar los modelos:}
\begin{enumerate}
    \item \textbf{Feature Engineering avanzado:} Crear variables derivadas más sofisticadas que capturen interacciones complejas entre variables temporales, de comunidad y de contenido.
    \item \textbf{Nuevos modelos:} Explorar arquitecturas de Deep Learning (LSTM para series temporales, Transformers para texto) y modelos de ensamble más complejos (Stacking, Blending).
    \item \textbf{Optimización exhaustiva:} Grid Search/Random Search más extenso, técnicas de AutoML, y validación temporal estratificada.
    \item \textbf{Mayor volumen de datos:} Ampliar el dataset con más publicaciones de diferentes períodos para capturar mayor variabilidad y mejorar generalización.
\end{enumerate}

\textbf{Valor del proyecto:} Aunque los modelos actuales no son aptos para producción, este trabajo establece una \textbf{línea base metodológica rigurosa} y documenta claramente las limitaciones de usar únicamente variables temporales y de metadata para predicción de engagement. El análisis proporciona insights valiosos sobre qué factores influyen en el engagement y establece el camino para futuras mejoras.

% =============== REFERENCIAS ===================
\newpage
\section*{Referencias}
\addcontentsline{toc}{section}{Referencias}

\begin{enumerate}[label={[\arabic*]}]
    \item \textbf{Moro, S., Rita, P., \& Vala, B. (2016).} Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach. \textit{Journal of Business Research}, 69(9), 3341-3351.
\end{enumerate}

\end{document}
